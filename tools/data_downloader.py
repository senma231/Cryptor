"""
äº¤æ˜“æ‰€å†å²æ•°æ®ä¸‹è½½å·¥å…·
æ”¯æŒå¸å®‰(Binance)å’ŒOKXäº¤æ˜“æ‰€
æ— éœ€APIå¯†é’¥,ä½¿ç”¨å…¬å¼€æ¥å£
"""

import requests
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Optional
import time

# å°è¯•å¯¼å…¥loguruï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨print
try:
    from loguru import logger
except:
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„loggeræ›¿ä»£å“
    class SimpleLogger:
        def info(self, msg): print(f"[INFO] {msg}")
        def debug(self, msg): print(f"[DEBUG] {msg}")
        def warning(self, msg): print(f"[WARNING] {msg}")
        def error(self, msg): print(f"[ERROR] {msg}")
        def success(self, msg): print(f"[SUCCESS] {msg}")
    logger = SimpleLogger()


class DataDownloader:
    """å†å²æ•°æ®ä¸‹è½½å™¨"""

    def __init__(self, exchange: str = 'binance'):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨

        Args:
            exchange: äº¤æ˜“æ‰€åç§° ('binance', 'okx', æˆ– 'htx')
        """
        self.exchange = exchange.lower()
        self.base_url = self._get_base_url()
        self.data_dir = Path(f'data/historical/{self.exchange}')
        self.data_dir.mkdir(parents=True, exist_ok=True)

    def _get_base_url(self) -> str:
        """è·å–äº¤æ˜“æ‰€APIåŸºç¡€URL"""
        urls = {
            'binance': 'https://api.binance.com',
            'okx': 'https://www.okx.com'
        }
        return urls.get(self.exchange, urls['binance'])

    def download_klines_binance(
        self,
        symbol: str,
        interval: str,
        start_time: str,
        end_time: Optional[str] = None,
        limit: int = 1000
    ) -> pd.DataFrame:
        """
        ä¸‹è½½å¸å®‰Kçº¿æ•°æ®

        Args:
            symbol: äº¤æ˜“å¯¹,å¦‚ 'BTCUSDT'
            interval: Kçº¿å‘¨æœŸ
                - 1m, 3m, 5m, 15m, 30m (åˆ†é’Ÿ)
                - 1h, 2h, 4h, 6h, 8h, 12h (å°æ—¶)
                - 1d, 3d (å¤©)
                - 1w (å‘¨)
                - 1M (æœˆ)
            start_time: å¼€å§‹æ—¶é—´ 'YYYY-MM-DD'
            end_time: ç»“æŸæ—¶é—´ 'YYYY-MM-DD' (é»˜è®¤ä¸ºä»Šå¤©)
            limit: å•æ¬¡è¯·æ±‚é™åˆ¶(æœ€å¤§1000)

        Returns:
            åŒ…å«Kçº¿æ•°æ®çš„DataFrame
        """
        # è½¬æ¢æ—¶é—´ä¸ºæ—¶é—´æˆ³
        start_ts = int(datetime.strptime(start_time, '%Y-%m-%d').timestamp() * 1000)
        if end_time:
            end_ts = int(datetime.strptime(end_time, '%Y-%m-%d').timestamp() * 1000)
        else:
            end_ts = int(datetime.now().timestamp() * 1000)

        all_data = []
        current_ts = start_ts

        logger.info(f"å¼€å§‹ä¸‹è½½ {symbol} {interval} Kçº¿æ•°æ®")
        logger.info(f"æ—¶é—´èŒƒå›´: {start_time} ~ {end_time or 'ä»Šå¤©'}")

        while current_ts < end_ts:
            # æ„é€ è¯·æ±‚URL
            url = f"{self.base_url}/api/v3/klines"
            params = {
                'symbol': symbol,
                'interval': interval,
                'startTime': current_ts,
                'endTime': end_ts,
                'limit': limit
            }

            # æ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 3
            retry_count = 0
            success = False

            while retry_count < max_retries and not success:
                try:
                    response = requests.get(url, params=params, timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°30ç§’
                    response.raise_for_status()
                    data = response.json()

                    if not data:
                        break

                    all_data.extend(data)
                    current_ts = data[-1][0] + 1  # ä¸‹ä¸€æ‰¹ä»æœ€åä¸€æ¡çš„ä¸‹ä¸€æ¯«ç§’å¼€å§‹

                    logger.info(f"å·²ä¸‹è½½ {len(all_data)} æ¡æ•°æ®...")
                    success = True

                    # é¿å…è¯·æ±‚è¿‡å¿«
                    time.sleep(0.1)

                except requests.exceptions.RequestException as e:
                    retry_count += 1
                    if retry_count < max_retries:
                        logger.warning(f"è¯·æ±‚å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({retry_count}/{max_retries}): {e}")
                        time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    else:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                        break

            if not success:
                break

        # è½¬æ¢ä¸ºDataFrame
        if not all_data:
            logger.warning("æœªä¸‹è½½åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()

        df = pd.DataFrame(all_data, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_volume', 'trades', 'taker_buy_base',
            'taker_buy_quote', 'ignore'
        ])

        # æ•°æ®ç±»å‹è½¬æ¢
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')

        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = df[col].astype(float)

        logger.info(f"âœ“ æˆåŠŸä¸‹è½½ {len(df)} æ¡Kçº¿æ•°æ®")
        return df

    def download_klines_okx(
        self,
        symbol: str,
        interval: str,
        start_time: str,
        end_time: Optional[str] = None
    ) -> pd.DataFrame:
        """
        ä¸‹è½½OKX Kçº¿æ•°æ®

        Args:
            symbol: äº¤æ˜“å¯¹,å¦‚ 'BTC-USDT'
            interval: Kçº¿å‘¨æœŸ
                - 1m, 3m, 5m, 15m, 30m (åˆ†é’Ÿ)
                - 1H, 2H, 4H (å°æ—¶,æ³¨æ„å¤§å†™)
                - 1D, 1W, 1M (å¤©/å‘¨/æœˆ,æ³¨æ„å¤§å†™)
            start_time: å¼€å§‹æ—¶é—´ 'YYYY-MM-DD'
            end_time: ç»“æŸæ—¶é—´ 'YYYY-MM-DD'

        Returns:
            åŒ…å«Kçº¿æ•°æ®çš„DataFrame
        """
        # è½¬æ¢intervalæ ¼å¼ (1h -> 1H, 1d -> 1D)
        interval_map = {
            '1m': '1m', '3m': '3m', '5m': '5m', '15m': '15m', '30m': '30m',
            '1h': '1H', '2h': '2H', '4h': '4H', '6h': '6H', '12h': '12H',
            '1d': '1D', '1w': '1W', '1M': '1M'
        }
        okx_interval = interval_map.get(interval, interval)

        # è½¬æ¢æ—¶é—´ä¸ºæ—¶é—´æˆ³(æ¯«ç§’)
        start_ts = int(datetime.strptime(start_time, '%Y-%m-%d').timestamp() * 1000)
        if end_time:
            end_ts = int(datetime.strptime(end_time, '%Y-%m-%d').timestamp() * 1000)
        else:
            end_ts = int(datetime.now().timestamp() * 1000)

        all_data = []

        logger.info(f"å¼€å§‹ä¸‹è½½ {symbol} {okx_interval} Kçº¿æ•°æ®")
        logger.info(f"æ—¶é—´èŒƒå›´: {start_time} ({start_ts}) ~ {end_time or 'ä»Šå¤©'} ({end_ts})")

        # OKX APIçš„æ­£ç¡®ç†è§£ï¼ˆç»è¿‡å¤§é‡å®é™…æµ‹è¯•éªŒè¯ï¼‰ï¼š
        # å®˜æ–¹æ–‡æ¡£è¯´æ˜ï¼š
        # - after: "Pagination of data to return records earlier than the requested ts"
        # - before: "Pagination of data to return records newer than the requested ts"
        #
        # å®é™…è¡Œä¸ºï¼ˆéå¸¸åç›´è§‰ï¼ï¼‰ï¼š
        # - ä¸å¸¦å‚æ•°ï¼šè¿”å›æœ€æ–°çš„100æ¡æ•°æ®ï¼ˆé™åºï¼šä»æ–°åˆ°æ—§ï¼‰
        # - before=Tï¼šè¿”å›æœ€æ–°çš„100æ¡æ•°æ®ï¼Œä½†**æ’é™¤**æ—¶é—´æˆ³>=Tçš„æ•°æ®ï¼ˆé™åºï¼‰
        # - after=Tï¼šè¿”å›æ—©äºTçš„100æ¡æ•°æ®ï¼ˆé™åºï¼šä»æ–°åˆ°æ—§ï¼‰
        #
        # beforeå‚æ•°çš„é—®é¢˜ï¼š
        # - before=Tåªæ˜¯è¿‡æ»¤æ‰>=Tçš„æ•°æ®ï¼Œä¸æ”¹å˜èµ·å§‹ç‚¹
        # - æ¯æ¬¡è¯·æ±‚éƒ½ä»æœ€æ–°æ—¶é—´å¼€å§‹ï¼Œå¯¼è‡´å¤§é‡é‡å¤æ•°æ®
        # - æ— æ³•ç”¨äºæ­£å¸¸çš„åˆ†é¡µä¸‹è½½
        #
        # æ­£ç¡®ç­–ç•¥ï¼šä½¿ç”¨afterå‚æ•°ä»æœ€æ–°å¾€æ—§çš„æ–¹å‘ä¸‹è½½
        # 1. ç¬¬ä¸€æ¬¡è¯·æ±‚ä½¿ç”¨after=end_ts+1ï¼Œè·å–end_tsåŠä¹‹å‰çš„100æ¡æ•°æ®
        # 2. åç»­è¯·æ±‚ä½¿ç”¨after=oldest_tsï¼Œç»§ç»­å¾€æ›´æ—§çš„æ–¹å‘è·å–
        # 3. åœæ­¢æ¡ä»¶ï¼šå½“è·å–åˆ°çš„æœ€æ—§æ—¶é—´æˆ³ <= start_tsæ—¶åœæ­¢

        url = f"{self.base_url}/api/v5/market/history-candles"
        after_ts = end_ts + 1  # afterå‚æ•°è¿”å›æ—©äºæŒ‡å®šæ—¶é—´æˆ³çš„æ•°æ®
        max_iterations = 100
        iteration = 0

        while iteration < max_iterations:
            iteration += 1

            params = {
                'instId': symbol,
                'bar': okx_interval,
                'limit': 100,
                'after': after_ts
            }

            # æ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 3
            retry_count = 0
            success = False

            while retry_count < max_retries and not success:
                try:
                    response = requests.get(url, params=params, timeout=30)
                    response.raise_for_status()
                    result = response.json()

                    if result['code'] != '0':
                        logger.error(f"APIé”™è¯¯: {result['msg']}")
                        break

                    data = result['data']
                    success = True

                except requests.exceptions.RequestException as e:
                    retry_count += 1
                    if retry_count < max_retries:
                        logger.warning(f"è¯·æ±‚å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({retry_count}/{max_retries}): {e}")
                        time.sleep(2)
                    else:
                        logger.error(f"è¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                        break

            if not success:
                break

            # ç»§ç»­å¤„ç†data
            if not data:
                logger.info("æ²¡æœ‰æ›´å¤šæ•°æ®ï¼Œåœæ­¢ä¸‹è½½")
                break

            # OKXä½¿ç”¨afterå‚æ•°æ—¶ï¼Œè¿”å›çš„æ•°æ®æŒ‰æ—¶é—´æˆ³é™åºæ’åˆ—ï¼ˆä»æ–°åˆ°æ—§ï¼‰
            newest_ts = int(data[0][0])   # æœ€æ–°çš„æ•°æ®ï¼ˆç¬¬ä¸€æ¡ï¼‰
            oldest_ts = int(data[-1][0])  # æœ€æ—§çš„æ•°æ®ï¼ˆæœ€åä¸€æ¡ï¼‰

            logger.debug(f"å½“å‰æ‰¹æ¬¡: newest={datetime.fromtimestamp(newest_ts/1000)}, oldest={datetime.fromtimestamp(oldest_ts/1000)}")
            logger.debug(f"ç›®æ ‡èŒƒå›´: start={datetime.fromtimestamp(start_ts/1000)}, end={datetime.fromtimestamp(end_ts/1000)}")

            # è¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„æ•°æ®
            filtered_data = [d for d in data if start_ts <= int(d[0]) <= end_ts]

            logger.debug(f"å½“å‰æ‰¹æ¬¡æ•°æ®: {len(data)} æ¡, è¿‡æ»¤å: {len(filtered_data)} æ¡")

            if filtered_data:
                all_data.extend(filtered_data)
                logger.info(f"å·²ä¸‹è½½ {len(all_data)} æ¡æ•°æ®...")

            # åœæ­¢æ¡ä»¶ï¼šå¦‚æœæœ€æ—§çš„æ•°æ®å·²ç»æ—©äºæˆ–ç­‰äºå¼€å§‹æ—¶é—´ï¼Œè¯´æ˜å·²ç»è¦†ç›–äº†æ•´ä¸ªæ—¶é—´èŒƒå›´
            if oldest_ts <= start_ts:
                logger.info(f"å·²è¦†ç›–å¼€å§‹æ—¶é—´ï¼Œåœæ­¢ä¸‹è½½")
                break

            # æ›´æ–°afterå‚æ•°ä¸ºå½“å‰æ‰¹æ¬¡æœ€æ—§çš„æ—¶é—´æˆ³
            # ä¸‹ä¸€æ¬¡è¯·æ±‚å°†è¿”å›æ—©äºoldest_tsçš„æ•°æ®
            after_ts = oldest_ts

            time.sleep(0.2)

        if not all_data:
            logger.warning("æœªä¸‹è½½åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()

        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(all_data, columns=[
            'timestamp', 'open', 'high', 'low', 'close',
            'volume', 'volume_currency', 'volume_currency_quote', 'confirm'
        ])

        df['timestamp'] = pd.to_datetime(df['timestamp'].astype(int), unit='ms')
        for col in ['open', 'high', 'low', 'close', 'volume']:
            df[col] = df[col].astype(float)

        df = df.sort_values('timestamp').reset_index(drop=True)

        logger.info(f"âœ“ æˆåŠŸä¸‹è½½ {len(df)} æ¡Kçº¿æ•°æ®")
        return df

    def download_klines_htx(
        self,
        symbol: str,
        interval: str,
        start_time: str,
        end_time: Optional[str] = None
    ) -> pd.DataFrame:
        """
        ä¸‹è½½HTX/ç«å¸ Kçº¿æ•°æ®

        Args:
            symbol: äº¤æ˜“å¯¹,å¦‚ 'BTCUSDT' (ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºå°å†™)
            interval: Kçº¿å‘¨æœŸ
                - 1m, 5m, 15m, 30m (åˆ†é’Ÿ)
                - 1h, 4h (å°æ—¶)
                - 1d, 1w, 1M (å¤©/å‘¨/æœˆ)
            start_time: å¼€å§‹æ—¶é—´ 'YYYY-MM-DD'
            end_time: ç»“æŸæ—¶é—´ 'YYYY-MM-DD' (å¯é€‰,é»˜è®¤ä»Šå¤©)

        Returns:
            åŒ…å«Kçº¿æ•°æ®çš„DataFrame
        """
        from tools.exchange_factory import HTXExchange

        logger.info(f"å¼€å§‹ä¸‹è½½HTX Kçº¿æ•°æ®: {symbol} {interval}")

        # HTXä½¿ç”¨å°å†™ç¬¦å·
        symbol_lower = symbol.lower()

        # è½¬æ¢æ—¶é—´æ ¼å¼
        start_ts = int(pd.Timestamp(start_time).timestamp())
        if end_time:
            end_ts = int(pd.Timestamp(end_time).timestamp())
        else:
            end_ts = int(pd.Timestamp.now().timestamp())

        # åˆ›å»ºHTXäº¤æ˜“æ‰€å®ä¾‹
        htx = HTXExchange(market_type='spot')

        # HTXæ¯æ¬¡æœ€å¤šè¿”å›2000æ¡æ•°æ®
        all_data = []
        current_ts = start_ts

        # è®¡ç®—æ¯æ ¹Kçº¿çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰
        interval_seconds = {
            '1m': 60, '5m': 300, '15m': 900, '30m': 1800,
            '1h': 3600, '4h': 14400,
            '1d': 86400, '1w': 604800, '1M': 2592000
        }.get(interval, 3600)

        while current_ts < end_ts:
            # è®¡ç®—æœ¬æ¬¡è¯·æ±‚çš„æ•°é‡
            remaining_bars = (end_ts - current_ts) // interval_seconds
            limit = min(2000, remaining_bars + 1)

            if limit <= 0:
                break

            logger.info(f"  ä¸‹è½½ {pd.Timestamp(current_ts, unit='s')} å¼€å§‹çš„ {limit} æ¡æ•°æ®...")

            # è·å–Kçº¿æ•°æ®
            df = htx.get_klines(symbol_lower, interval, limit=limit)

            if df is None or df.empty:
                logger.warning(f"  æœªè·å–åˆ°æ•°æ®")
                break

            # è¿‡æ»¤æ—¶é—´èŒƒå›´
            df = df[df['timestamp'] >= pd.Timestamp(current_ts, unit='s')]
            df = df[df['timestamp'] <= pd.Timestamp(end_ts, unit='s')]

            if not df.empty:
                all_data.append(df)
                # æ›´æ–°å½“å‰æ—¶é—´æˆ³åˆ°æœ€åä¸€æ¡æ•°æ®çš„æ—¶é—´
                current_ts = int(df['timestamp'].max().timestamp()) + interval_seconds
                logger.info(f"  âœ“ è·å– {len(df)} æ¡æ•°æ®")
            else:
                break

            # é¿å…è¯·æ±‚è¿‡å¿«
            import time
            time.sleep(0.2)

        if not all_data:
            logger.error("æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        df = pd.concat(all_data, ignore_index=True)
        df = df.drop_duplicates(subset=['timestamp']).sort_values('timestamp').reset_index(drop=True)

        logger.info(f"âœ“ æˆåŠŸä¸‹è½½ {len(df)} æ¡Kçº¿æ•°æ®")
        return df

    def download_and_save(
        self,
        symbol: str,
        interval: str,
        start_time: str,
        end_time: Optional[str] = None,
        format: str = 'parquet'
    ) -> str:
        """
        ä¸‹è½½å¹¶ä¿å­˜æ•°æ®åˆ°æœ¬åœ°

        Args:
            symbol: äº¤æ˜“å¯¹
            interval: Kçº¿å‘¨æœŸ
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            format: ä¿å­˜æ ¼å¼ ('parquet', 'csv')

        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        # æ ¹æ®äº¤æ˜“æ‰€ä¸‹è½½æ•°æ®
        if self.exchange == 'binance':
            df = self.download_klines_binance(symbol, interval, start_time, end_time)
        elif self.exchange == 'okx':
            # OKXä½¿ç”¨æ¨ªæ åˆ†éš”
            symbol_okx = symbol.replace('USDT', '-USDT').replace('BTC', 'BTC-')
            df = self.download_klines_okx(symbol_okx, interval, start_time, end_time)
        elif self.exchange == 'htx':
            df = self.download_klines_htx(symbol, interval, start_time, end_time)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„äº¤æ˜“æ‰€: {self.exchange}")

        if df.empty:
            logger.error("æ•°æ®ä¸ºç©º,å–æ¶ˆä¿å­˜")
            return ""

        # æ„é€ æ–‡ä»¶å
        filename = f"{symbol}_{interval}_{start_time}_{end_time or 'now'}.{format}"
        filepath = self.data_dir / symbol / filename
        filepath.parent.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜æ–‡ä»¶
        if format == 'parquet':
            df.to_parquet(filepath, index=False)
        elif format == 'csv':
            df.to_csv(filepath, index=False)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")

        logger.info(f"âœ“ æ•°æ®å·²ä¿å­˜è‡³: {filepath}")
        logger.info(f"  æ•°æ®æ¡æ•°: {len(df)}")
        logger.info(f"  æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        logger.info(f"  æ–‡ä»¶å¤§å°: {filepath.stat().st_size / 1024:.2f} KB")

        return str(filepath)

    def get_popular_symbols(self) -> List[str]:
        """è·å–çƒ­é—¨äº¤æ˜“å¯¹åˆ—è¡¨"""
        if self.exchange == 'binance':
            return [
                'BTCUSDT', 'ETHUSDT', 'BNBUSDT',
                'SOLUSDT', 'XRPUSDT', 'ADAUSDT',
                'DOGEUSDT', 'AVAXUSDT', 'MATICUSDT', 'DOTUSDT'
            ]
        elif self.exchange == 'okx':
            return [
                'BTC-USDT', 'ETH-USDT', 'SOL-USDT',
                'XRP-USDT', 'ADA-USDT', 'DOGE-USDT'
            ]
        elif self.exchange == 'htx':
            return [
                'BTCUSDT', 'ETHUSDT', 'SOLUSDT',
                'XRPUSDT', 'ADAUSDT', 'DOGEUSDT'
            ]
        return []


def main():
    """å‘½ä»¤è¡Œä½¿ç”¨ç¤ºä¾‹"""
    import argparse

    parser = argparse.ArgumentParser(description='äº¤æ˜“æ‰€å†å²æ•°æ®ä¸‹è½½å·¥å…·')
    parser.add_argument('--exchange', type=str, default='binance',
                        choices=['binance', 'okx', 'htx'], help='äº¤æ˜“æ‰€')
    parser.add_argument('--symbol', type=str, required=True,
                        help='äº¤æ˜“å¯¹,å¦‚ BTCUSDT')
    parser.add_argument('--interval', type=str, default='1h',
                        help='Kçº¿å‘¨æœŸ,å¦‚ 1m, 5m, 1h, 1d')
    parser.add_argument('--start', type=str, required=True,
                        help='å¼€å§‹æ—¥æœŸ YYYY-MM-DD')
    parser.add_argument('--end', type=str, default=None,
                        help='ç»“æŸæ—¥æœŸ YYYY-MM-DD (é»˜è®¤ä»Šå¤©)')
    parser.add_argument('--format', type=str, default='parquet',
                        choices=['parquet', 'csv'], help='ä¿å­˜æ ¼å¼')

    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    logger.remove()
    logger.add(
        lambda msg: print(msg, end=''),
        format="<green>{time:HH:mm:ss}</green> | <level>{message}</level>"
    )

    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     äº¤æ˜“æ‰€å†å²æ•°æ®ä¸‹è½½å·¥å…·                     â•‘
â•‘     Historical Data Downloader                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

äº¤æ˜“æ‰€: {args.exchange.upper()}
äº¤æ˜“å¯¹: {args.symbol}
å‘¨  æœŸ: {args.interval}
æ—¶é—´æ®µ: {args.start} ~ {args.end or 'ä»Šå¤©'}
æ ¼  å¼: {args.format.upper()}
    """)

    try:
        downloader = DataDownloader(args.exchange)
        filepath = downloader.download_and_save(
            args.symbol,
            args.interval,
            args.start,
            args.end,
            args.format
        )

        if filepath:
            print(f"\nâœ… ä¸‹è½½æˆåŠŸ!")
            print(f"æ–‡ä»¶ä½ç½®: {filepath}")
            print(f"\nğŸ’¡ æç¤º: æ‚¨å¯ä»¥ä½¿ç”¨æ­¤æ•°æ®è¿›è¡Œå›æµ‹:")
            print(f"   python main.py --mode backtest --strategy your_strategy \\")
            print(f"     --start {args.start} --end {args.end or datetime.now().strftime('%Y-%m-%d')}")

    except Exception as e:
        logger.exception(f"ä¸‹è½½å¤±è´¥: {e}")
        return 1

    return 0


if __name__ == '__main__':
    import sys
    sys.exit(main())
